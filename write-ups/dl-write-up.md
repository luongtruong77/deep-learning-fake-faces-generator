# Artistic Faces Generator
#### Can we synthesize fake faces using deep learning?
---

Steven L Truong

---

## Abstract
---
In this project, I will apply the method of [Generative Adversarial Networks (GAN)](https://arxiv.org/abs/1406.2661) to generate low-quality facial-like images. The model consists of two models being trained simultaneously by an adversarial process.A `generator` ("the artist") learns to create images that look real by taking a random distribution (typically Gaussian) and outputs images while a `discriminator` ("the art critic") learns to tell real images apart from fakes. The *BinaryCrossEntropy* function is used to optimize the cost. The training process goes on until some equilibrium being reached, meaning the `discriminator` can not correctly separate fakes from reals anymore; this is when we have our model.

The generator can be found [HERE](https://share.streamlit.io/luongtruong77/deep-learning-fake-faces-generator/main/app.py)

## Design
---
- Proposed in 2014 by Ian Goodfellow, GAN has been a major player in the field of Deep Learning and Artificial Intelligence to generate new images from the train dataset.
- I would like to apply GAN to build a model to generate completely new faces (not from real people) from a collection of over 200,000 celebrity faces.


## Data
---
[**CelebFaces Attributes Dataset (CelebA)**](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) is a large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations. The images in this dataset cover large pose variations and background clutter. (Multimedia Laboratory, The Chinese University of Hong Kong). 
>Random 25 instances from the dataset:
![](https://github.com/luongtruong77/deep-learning-fake-faces-generator/blob/main/figures/samples.png?raw=true)

## Algorithm
---

#### The generator and the discriminator
- The `generator`: uses `tf.keras.layers.Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). Start with a Dense layer that takes this seed as input, then upsample several times until you reach the desired image size of 64x64x3 or 128x128x3 depends on how we want our model to be. We use `tf.keras.layers.LeakyReLU` activation for each layer, except the output layer which uses `sigmoid`.
- The `discriminator`: is a `CNN-based` images classifier to classify the images generated by the generator whether real or fake. The model will be trained to output positive values for real images and negative for fake images.

#### The training phases
- Training the model: each training iteration is divided into two phases:
    - In the first phase, we train the `discriminator`. A batch of real images is sampled from the training set and is completed with an equal number of fake images produced by the `generator`.
The labels are set to **0** for fake images and **1** for real images, and the `discriminator` is trained on this labeled batch for 1 step, using the `binary cross-entropy loss`.
Importantly, **backpropagation** only optimizes the weights of the `discriminator` during this phase.
    - In the 2nd phase, we train the `generator`. We first use it to produce another batch of fake images, and once again the `discriminator` is used to tell whether the images are fake or real.
This time we do not add real images in the batch, and all labels are set to **1 (real)**. In other words, we want the `generator` to produce images that the `discriminator` will (wrongly) believe to be real.
Crucially, the weights of the `discriminator` are frozen (set trainable_param = False) during this step, so **backpropagation** only affects the weights of the `generator`.

#### Results
>The results after 30epochs
![](https://github.com/luongtruong77/deep-learning-fake-faces-generator/blob/main/generated_images/30epochs_64x64_full.png?raw=true)



>The results after 60epochs
![](https://github.com/luongtruong77/deep-learning-fake-faces-generator/blob/main/generated_images/60epochs_64x64_full.png?raw=true)


#### Comments
As we can see, the model somewhat generates general patterns and shapes of faces, but they don't look exaclty pretty because the results are for just 30 and 60 epochs. 
This model is very computationally expensive to run with higher number of epochs. I let my model runs on Google Cloud jupyter lab with **Tesla P100** GPU backend with the. The results will typically improve around ~150epochs.



## Tools
---
- Python
- Pandas
- Numpy
- Matplotlib
- Tensorflow
- Keras
- Google Cloud Platform (Compute Engine VM and Google Colab)
- Streamlit

## Communication
---
- All the notebooks can be found [HERE.](https://github.com/luongtruong77/deep-learning-fake-faces-generator/tree/main/notebooks)
- The generator app can be found [HERE.](https://share.streamlit.io/luongtruong77/deep-learning-fake-faces-generator/main/app.py)
- The presentation can be found [HERE.]()








